{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'brown'>Politics Project (공정배 민유진 유영재 장은경)<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>주제 : 네이버 상위권 뉴스와 정부 지지율 관계성 파악<font>\n",
    "> - 정치 / 경제 / 사회 3가지 카테고리를 이용\n",
    "- 기사의 헤드라인의 키워드 빈도수를 이용\n",
    "- 기사 랭크 top5 와 top30 나눠서 분석\n",
    "- 문재인 정부의 1년 간의 지지율 데이터 추출 및 관계도 파악 (2017년 11월 1일 ~ 2018년 11월 15일)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'red'>기사 크롤링 함수<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 크롤링 하는 함수\n",
    "def crawling_news(startDay, endDay, numOfNews):\n",
    "    Day = []\n",
    "    polTitle = []\n",
    "    ecoTitle = []\n",
    "    socTitle = []\n",
    "    totalTitle = []\n",
    "    \n",
    "    # 시작과 끝 날짜 입력\n",
    "    startDay, endDay = str(startDay), str(endDay)\n",
    "    \n",
    "    # 날짜목록 만들기\n",
    "    dayList = pd.date_range(start = startDay, end = endDay)\n",
    "    dayList = dayList.strftime('%Y%m%d').tolist()\n",
    "    \n",
    "    # 카테고리\n",
    "    categorys = ['100', '101', '102']  # 100 : 정치 / 101 : 경제 / 102 : 사회\n",
    "    \n",
    "    # 크롤링\n",
    "    url = 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId={}&date='\n",
    "    \n",
    "    for category in categorys:\n",
    "        urlBasic = url.format(category)\n",
    "    \n",
    "        for day in dayList:\n",
    "            # html 수집\n",
    "            urlDay = urlBasic + day\n",
    "            html = urlopen(urlDay)\n",
    "            soup = BeautifulSoup(html, \"lxml\")\n",
    "        \n",
    "            # 기사 헤드라인 수집\n",
    "            newsTitle = soup.find_all('div', 'ranking_headline')\n",
    "        \n",
    "            for n in range(numOfNews):\n",
    "                # 정치 기사만 수집\n",
    "                if category == '100':\n",
    "                    Day.append(day)\n",
    "                    polTitle.append(newsTitle[n].get_text().strip())\n",
    "                \n",
    "                # 경제 기사만 수집\n",
    "                if category == '101':\n",
    "                    ecoTitle.append(newsTitle[n].get_text().strip())\n",
    "                \n",
    "                # 사회 기사만 수집\n",
    "                if category == '102':\n",
    "                    socTitle.append(newsTitle[n].get_text().strip())\n",
    "    \n",
    "    # 정치/경제/사회 헤드라인 합치기 과정\n",
    "    for n in range(len(polTitle)):\n",
    "        tmpTitle =  polTitle[n] + ' ' + ecoTitle[n] + ' ' + socTitle[n]\n",
    "        totalTitle.append(tmpTitle)\n",
    "    \n",
    "    # 데이터 프레임 생성\n",
    "    data = {'날짜' : Day, '정치' : polTitle, '경제' : ecoTitle, '사회' : socTitle, '종합' : totalTitle}\n",
    "    news = pd.DataFrame(data)\n",
    "    \n",
    "    return news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'red'>대통령 지지율 크롤링 함수<font>\n",
    "> - 취임부터 2018년 11월까지 데이터 추출\n",
    "- 출처: 위키피디아, 한국갤럽\n",
    "- https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EB%8C%80%ED%86%B5%EB%A0%B9_%EC%A7%80%EC%A7%80%EC%9C%A8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 대통령 지지율 크롤링 함수\n",
    "def support():\n",
    "    # 위키피디아 html 가져오기\n",
    "    url  = 'https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EB%8C%80%ED%86%B5%EB%A0%B9_%EC%A7%80%EC%A7%80%EC%9C%A8#cite_note-%EC%B6%94%EC%84%9D-8'\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    div_title = soup.find_all('tbody')[6].find_all('td')\n",
    "    \n",
    "    # 이중 리스트 구조를 이용해 각 주의 지지율 리스트 만들기\n",
    "    weekSupportList = []\n",
    "    weekSupport = []\n",
    "    for n in range(len(div_title)):\n",
    "        element = div_title[n].get_text().strip()\n",
    "        if '미조사' in element:\n",
    "            weekSupport.append('NA')\n",
    "            continue\n",
    "        if '월' in element:\n",
    "            weekSupport = []\n",
    "            weekSupportList.append(weekSupport)\n",
    "        weekSupport.append(element)\n",
    "    \n",
    "    # 주 정보에서 년도 월 추출\n",
    "    YEAR=[]\n",
    "    MONTH=[]\n",
    "    for element in weekSupportList:\n",
    "        pattern = re.compile('(\\d{4}\\w)')\n",
    "        year = int(pattern.search(element[0]).group()[:-1])\n",
    "        pattern = re.compile('(\\s\\d{1,2}\\w)')\n",
    "        month = str(int(pattern.search(element[0]).group()[:-1])).zfill(2)\n",
    "    \n",
    "        YEAR.append(year)\n",
    "        MONTH.append(month)\n",
    "    \n",
    "    # 년도와 월 합치기\n",
    "    DATE=[]\n",
    "    for i in range(len(MONTH)):\n",
    "        date= '{year}{month}'.format(year=YEAR[i], month=MONTH[i])\n",
    "        DATE.append(int(date))\n",
    "        \n",
    "    uniqueDate = set(DATE)\n",
    "    uniqueDate = list(uniqueDate)\n",
    "    \n",
    "    # 지지율 추출\n",
    "    PERCENT=[]\n",
    "    for i in range(len(weekSupportList)):\n",
    "        percent = weekSupportList[i][1]\n",
    "        PERCENT.append(percent)\n",
    "    \n",
    "    print(len(DATE))\n",
    "    print(len(PERCENT))\n",
    "    \n",
    "    # 초기 데이터 프레임 생성\n",
    "    data = pd.DataFrame({\"날짜\": DATE,\"지지율\": PERCENT})\n",
    "    data = data.set_index(\"날짜\")\n",
    "    \n",
    "    # 월 지지율을 마지막 주의 지지율로 대체\n",
    "    date = []\n",
    "    support = []\n",
    "    for i in range(len(uniqueDate)):\n",
    "        if data.loc[uniqueDate[i]].iloc[-1][0] == 'NA':\n",
    "            support.append(data.loc[uniqueDate[i]].iloc[-2][0])\n",
    "        else:\n",
    "            support.append(data.loc[uniqueDate[i]].iloc[-1][0])\n",
    "        date.append(uniqueDate[i])\n",
    "        \n",
    "    # 최종 데이터 프레임 생성\n",
    "    result = pd.DataFrame({'날짜' : date, '지지율' : support})\n",
    "    result.sort_values(by = '날짜', inplace=True)\n",
    "    result = result.iloc[5:]  # 1년간의 데이터만 추출\n",
    "    result.set_index(\"날짜\", inplace=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'red'>키워드 추출하는 함수<font>\n",
    "> - 빈도수가 높은 순으로 정렬\n",
    "- 원하는 카테고리를 정해서 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# 상위 키워드 뽑아내는 함수\n",
    "def extract_keyword(yearMonth, numOfWord, category, data,filterWord=[]):\n",
    "    \n",
    "    noFilterNoun = []       # 정제되지 않은 단어를 담을 공간\n",
    "    filterNoun = []         # 정제된 단어를 담을 공간\n",
    "    wordList = []           # 정제하고 빈도까지 체크한 단어를 담을 공간\n",
    "    wordFreq = []           # 정제한 단어의 빈도 수를 담을 공간\n",
    "    \n",
    "    # 년도와 월 필터\n",
    "    day = re.compile('{}\\d+'.format(str(yearMonth)))\n",
    "    \n",
    "    # 지정한 년, 월에 해당하는 단어만 추출하는 과정\n",
    "    kkma = Kkma()\n",
    "    for n in range(len(data['종합'])):\n",
    "        if day.search(str(data['날짜'][n])):\n",
    "            noFilterNoun.extend(kkma.nouns(data['{}'.format(category)][n]))\n",
    "    \n",
    "    # 단어 정제 과정\n",
    "    for word in noFilterNoun:\n",
    "        if len(word) == 1: continue\n",
    "        elif word in filterWord: continue\n",
    "        filterNoun.append(word)\n",
    "    \n",
    "    # 빈도수가 높은 단어 추출\n",
    "    cnt = Counter(filterNoun)\n",
    "    for word, freq in cnt.most_common(numOfWord):\n",
    "        wordList.append(word)\n",
    "        wordFreq.append(freq)\n",
    "    \n",
    "    # 데이터 프레임 형성\n",
    "    colName = [(yearMonth, '단어'), (yearMonth, '빈도')]\n",
    "    \n",
    "    df = pd.DataFrame({'단어' :wordList, '빈도':wordFreq})\n",
    "    df.rename(index=str, columns={'단어' : colName[0], '빈도' : colName[1]}, inplace=True)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns, names=['날짜', '종류'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'red'>단어 필터<font>\n",
    "> 버전을 2가지로 형성 (많은 키워드 수집을 위한 약한 필터 / 임팩트 있는 키워드 수집을 위한 강한 필터)\n",
    "- 정치\n",
    "- 경제\n",
    "- 사회\n",
    "- 종합 (정치 경제 사회 모두를 한꺼번에 고려한 것)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정치 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약한 필터\n",
    "polMeanlessWordsWeak = []\n",
    "polRepetiveWordsWeak = []\n",
    "polFilterWordsWeak = polMeanlessWordsWeak + polRepetiveWordsWeak\n",
    "\n",
    "# 강한 필터\n",
    "polMeanlessWordsStr = []\n",
    "polRepetiveWordsStr = []\n",
    "polFilterWordsStr = polMeanlessWordsStr + polRepetiveWordsStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경제 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약한 필터\n",
    "ecoMeanlessWordsWeak = []\n",
    "ecoRepetiveWordsWeak = []\n",
    "ecoFilterWordsWeak = ecoMeanlessWordsWeak + ecoRepetiveWordsWeak\n",
    "\n",
    "# 강한 필터\n",
    "ecoMeanlessWordsStr = ['종합','단독','10','11','내년','한국','경제','주택자','이유','회장','개월','국민','13',\n",
    "                    '종합2보']\n",
    "ecoRepetiveWordsStr = ['파리','게뜨','군제','코스','패딩','가상','화폐','비트코','비트','상화','상화폐','거래'\n",
    "                    '동연','군산','공장','금호','조현','대한','양호','바이오','항공','압수','수색',\n",
    "                    '부세']\n",
    "ecoFilterWordsStr = ecoMeanlessWordsStr + ecoRepetiveWordsStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사회 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약한 필터\n",
    "socMeanlessWordsWeak = []\n",
    "socRepetiveWordsWeak = []\n",
    "socFilterWordsWeak = socMeanlessWordsWeak + socRepetiveWordsWeak\n",
    "\n",
    "# 강한 필터\n",
    "socMeanlessWordsStr = []\n",
    "socRepetiveWordsStr = []\n",
    "socFilterWordsStr = socMeanlessWordsStr + socRepetiveWordsStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 종합 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약한 필터\n",
    "totalMeanlessWordsWeak = []\n",
    "totalRepetiveWordsWeak = []\n",
    "totalFilterWordsWeak = totalMeanlessWordsWeak + totalRepetiveWordsWeak\n",
    "\n",
    "# 강한 필터\n",
    "totalMeanlessWordsStr = []\n",
    "totalRepetiveWordsStr = []\n",
    "totalFilterWordsStr = totalMeanlessWordsStr + totalRepetiveWordsStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'red'>main 함수<font>\n",
    "> - extract_keyword 내부에서 호출 함수 이용\n",
    "- 키워드를 얻기 위한 자잘한 과정들을 내부적으로 모듈화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(startDay, endDay, numOfWord, category, data, filterWord=[]):\n",
    "    \n",
    "    # 날짜 목록 만들기\n",
    "    yearMonthList = pd.period_range(start=startDay, end=endDay, freq='M')\n",
    "    yearMonthList = yearMonthList.strftime('%Y%m').tolist()\n",
    "    \n",
    "    # 정제한 키워드 단어를 담을 데이터 프레임\n",
    "    resultWords = pd.DataFrame()\n",
    "    \n",
    "    # 키워드 뽑아내기 (기존에 만든 extract_keyword 함수 호출)\n",
    "    for yearMonth in yearMonthList:\n",
    "        tmpDf = extract_keyword(yearMonth, numOfWord, category, data, filterWord)\n",
    "        resultWords = pd.concat([resultWords, tmpDf], axis=1)\n",
    "    \n",
    "    return resultWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'red'>전체적인 동작<font>\n",
    "> - 기사 크롤링 함수 동작\n",
    "- 정부 지지율 크롤링 함수 동작\n",
    "- main 함수로 키워드 추출\n",
    "- 데이터 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기사 크롤링 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsTop30 = crawling_news(20171101, 20181115, 30)\n",
    "newsTop30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사 TOP 30 파일 저장\n",
    "\n",
    "newsTop30.to_csv('data/naver_news_top30.csv', sep=',', encoding='UTF-8')\n",
    "newsTop30.to_excel('data/naver_news_top30.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 뉴스 헤드라인 파일 읽어오기\n",
    "\n",
    "newsTop30 = pd.read_csv('data/naver_news_top30.csv', encoding='UTF-8')\n",
    "newsTop30.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "newsTop30.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정부 지지율 크롤링 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "governmentSupport = support()\n",
    "governmentSupport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정부 지지율 파일 저장\n",
    "\n",
    "governmentSupport.to_csv('data/governmentSupport.csv')\n",
    "governmentSupport.to_excel('data/governmentSupport.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정부 지지율 파일 읽어오기\n",
    "\n",
    "governmentSupport = pd.read_csv('data/governmentSupport.csv', encoding='UTF-8')\n",
    "governmentSupport.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "governmentSupport.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main 함수 동작 > 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalWords30 = main(20171101, 20181101, 50, '종합', news, tmpFilter)\n",
    "totalWords30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 파일 저장\n",
    "\n",
    "totalWords30.to_csv('data/keyword_total_top30.csv', sep=',', encoding='UTF-8')\n",
    "totalWords30.to_excel('data/keyword_total_top30.xlsx', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 파일 읽어오기\n",
    "\n",
    "newsTop30 = pd.read_csv('data/keyword_total_top30.csv', encoding='UTF-8')\n",
    "newsTop30.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "newsTop30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
